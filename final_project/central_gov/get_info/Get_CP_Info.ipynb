{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I'm gonna open the csv that has names & links for leaders in the central party\n",
    "\n",
    "### Use beautiful soup to open each link, scrape, save to a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"party_leader_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, there are four types of links\n",
    "\n",
    "1. http://cpc.people.com.cn/n1/2017/1025/c414940-296088**\n",
    "\n",
    "2. http://cpc.people.com.cn/n1/2018/0318/c64094-********-**\n",
    "\n",
    "3. http://cpc.people.com.cn/n1/2018/0315/c64387-********-**\n",
    "\n",
    "4. http://renshi.people.com.cn/n1/2018/0323/c139617-29884657.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c414940 links\n",
    "\n",
    "# raw_html = requests.get(\"http://cpc.people.com.cn/n1/2017/1025/c414940-29608803.html\").content\n",
    "# info = BeautifulSoup(raw_html, \"html.parser\")\n",
    "# resume = info.find(\"div\", attrs={\"class\":\"people_text\"})\n",
    "# name = resume.find(\"h2\").text\n",
    "# picture = resume.find(\"img\")[\"src\"]\n",
    "# info_list = resume.find_all(\"p\")\n",
    "# short_bio = info_list[1].text\n",
    "# current_status = info_list[2].text\n",
    "# additional_info = info_list[-2].text\n",
    "# publish_date = info_list[-1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #for c64094 and c64387 links\n",
    "\n",
    "# raw_html = requests.get(\"http://cpc.people.com.cn/n1/2018/0318/c64094-29873799-15.html\").content\n",
    "# info = BeautifulSoup(raw_html, \"html.parser\")\n",
    "# resume = info.find(\"div\", attrs={\"class\":\"show_text\"})\n",
    "# info_list = resume.find_all(\"p\")\n",
    "# name = info_list[1].text\n",
    "# picture = resume.find(\"img\")[\"src\"]\n",
    "# short_bio = info_list[2].text\n",
    "# current_status = info_list[3].text\n",
    "# additional_info = info_list[-1].text\n",
    "# publish_date = info.find(\"p\", attrs = {\"class\" : \"sou\"}).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for http://renshi.people.com.cn/n1/2018/0323/c139617-29884657.html\n",
    "\n",
    "# raw_html = requests.get(\"http://renshi.people.com.cn/n1/2018/0323/c139617-29884657.html\").content\n",
    "# info = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "# resume = info.find(\"div\", attrs={\"class\":\"show_text\"})\n",
    "# info_list = resume.find_all(\"p\")\n",
    "# name = info_list[1].text\n",
    "# picture = info_list[2].find(\"img\")[\"src\"]\n",
    "# short_bio = info_list[3].text\n",
    "# current_status = info_list[4].text\n",
    "# additional_info = info_list[-9].text\n",
    "# additional_info\n",
    "# publish_date = info.find(\"p\", attrs = {\"class\" : \"sou\"}).text\n",
    "\n",
    "# for data in info_list[5:-9]:\n",
    "#     print(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leader_info(column):\n",
    "    try:\n",
    "        if \"c414940\" in column[\"link\"]:\n",
    "            leader_info_dict = {}\n",
    "\n",
    "            raw_html = requests.get(column[\"link\"]).content\n",
    "            info = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "            resume = info.find(\"div\", attrs={\"class\":\"people_text\"})\n",
    "            name = resume.find(\"h2\").text\n",
    "            picture = resume.find(\"img\")[\"src\"]\n",
    "            info_list = resume.find_all(\"p\")\n",
    "            short_bio = info_list[1].text\n",
    "            current_status = info_list[2].text\n",
    "            additional_info = info_list[-2].text\n",
    "            publish_date = info_list[-1].text\n",
    "\n",
    "            leader_info_dict.update({\n",
    "                \"name\" : name,\n",
    "                \"picture_url\" : picture,\n",
    "                \"short_bio\" : short_bio,\n",
    "                \"current_status\" : current_status,\n",
    "                \"additional_info\" : additional_info,\n",
    "                \"publish_date\" : publish_date,\n",
    "                \"url\" : column[\"link\"]\n",
    "            })\n",
    "\n",
    "            leader_info_list.append(leader_info_dict)\n",
    "\n",
    "            for data in info_list[3:-2]:\n",
    "                leader_resume_dict = {}\n",
    "                try:\n",
    "                    year = data.text.split(\"年\")[0]\n",
    "                    content = data.text.split(\"年\")[1]\n",
    "                    leader_resume_dict.update({\n",
    "                        \"name\" : name,\n",
    "                        \"year\" : year,\n",
    "                        \"content\" : content,\n",
    "                        \"url\" : column[\"link\"]\n",
    "                    })\n",
    "                except:\n",
    "                    content = data.text\n",
    "                    leader_resume_dict.update({\n",
    "                        \"name\" : name,\n",
    "                        \"content\" : content,\n",
    "                        \"url\" : column[\"link\"]\n",
    "                    })\n",
    "                leader_resume_list.append(leader_resume_dict)\n",
    "\n",
    "\n",
    "        if \"c64094\" in column[\"link\"] or \"c64387\" in column[\"link\"]:\n",
    "            leader_info_dict = {}\n",
    "\n",
    "            raw_html = requests.get(column[\"link\"]).content\n",
    "            info = BeautifulSoup(raw_html, \"html5lib\")\n",
    "            resume = info.find(\"div\", attrs={\"class\":\"show_text\"})\n",
    "            info_list = resume.find_all(\"p\")\n",
    "            \n",
    "            if column[\"link\"] == \"http://cpc.people.com.cn/n1/2018/0318/c64094-29873799-15.html\":\n",
    "                name = info_list[0].text\n",
    "\n",
    "                picture = \"NaN\"\n",
    "                short_bio = info_list[1].text\n",
    "                current_status = info_list[2].text\n",
    "                if \"第\" in info_list[-1].text:\n",
    "                    additional_info = info_list[-1].text\n",
    "                elif \"第\" in info_list[-2].text:\n",
    "                    additional_info = info_list[-2].text\n",
    "                else:\n",
    "                    additional_info = info_list[-3].text\n",
    "                publish_date = info.find(\"p\", attrs = {\"class\" : \"sou\"}).text\n",
    "\n",
    "            \n",
    "                leader_info_dict.update({\n",
    "                    \"name\" : name,\n",
    "                    \"picture_url\" : picture,\n",
    "                    \"short_bio\" : short_bio,\n",
    "                    \"current_status\" : current_status,\n",
    "                    \"additional_info\" : additional_info,\n",
    "                    \"url\" : column[\"link\"],\n",
    "                    \"publish_date\" : publish_date\n",
    "                })\n",
    "                leader_info_list.append(leader_info_dict)\n",
    "\n",
    "                \n",
    "                for data in info_list[4:-1]:\n",
    "                    leader_resume_dict = {}\n",
    "                    try:\n",
    "                        year = data.text.split(\"年\")[0]\n",
    "                        content = data.text.split(\"年\")[1]\n",
    "                        leader_resume_dict.update({\n",
    "                            \"name\" : name,\n",
    "                            \"year\" : year,\n",
    "                            \"url\" : column[\"link\"],\n",
    "                            \"content\" : content\n",
    "                        })\n",
    "                    except:\n",
    "                        content = data.text\n",
    "                        leader_resume_dict.update({\n",
    "                            \"name\" : name,\n",
    "                            \"url\" : column[\"link\"],\n",
    "                            \"content\" : content\n",
    "                        })\n",
    "                    leader_resume_list.append(leader_resume_dict)\n",
    "                \n",
    "            else:\n",
    "                name = info_list[1].text\n",
    "                picture = resume.find(\"img\")[\"src\"]\n",
    "                short_bio = info_list[2].text\n",
    "                current_status = info_list[3].text\n",
    "                if \"第\" in info_list[-1].text:\n",
    "                    additional_info = info_list[-1].text\n",
    "                elif \"第\" in info_list[-2].text:\n",
    "                    additional_info = info_list[-2].text\n",
    "                else:\n",
    "                    additional_info = info_list[-3].text\n",
    "                publish_date = info.find(\"p\", attrs = {\"class\" : \"sou\"}).text\n",
    "                leader_info_list.append(leader_info_dict)\n",
    "            \n",
    "            \n",
    "                leader_info_dict.update({\n",
    "                    \"name\" : name,\n",
    "                    \"picture_url\" : picture,\n",
    "                    \"short_bio\" : short_bio,\n",
    "                    \"current_status\" : current_status,\n",
    "                    \"additional_info\" : additional_info,\n",
    "                    \"url\" : column[\"link\"],\n",
    "                    \"publish_date\" : publish_date\n",
    "                })\n",
    "            \n",
    "                for data in info_list[4:-1]:\n",
    "                    leader_resume_dict = {}\n",
    "                    try:\n",
    "                        year = data.text.split(\"年\")[0]\n",
    "                        content = data.text.split(\"年\")[1]\n",
    "                        leader_resume_dict.update({\n",
    "                            \"name\" : name,\n",
    "                            \"year\" : year,\n",
    "                            \"url\" : column[\"link\"],\n",
    "                            \"content\" : content\n",
    "                        })\n",
    "                    except:\n",
    "                        content = data.text\n",
    "                        leader_resume_dict.update({\n",
    "                            \"name\" : name,\n",
    "                            \"url\" : column[\"link\"],\n",
    "                            \"content\" : content\n",
    "                        })\n",
    "                    leader_resume_list.append(leader_resume_dict)                \n",
    "                \n",
    "            \n",
    "            \n",
    "        if \"renshi\" in column[\"link\"]:\n",
    "            leader_info_dict = {}\n",
    "\n",
    "            raw_html = requests.get(column[\"link\"]).content\n",
    "            info = BeautifulSoup(raw_html, \"html.parser\")\n",
    "\n",
    "            resume = info.find(\"div\", attrs={\"class\":\"show_text\"})\n",
    "            info_list = resume.find_all(\"p\")\n",
    "            name = info_list[1].text\n",
    "            picture = info_list[2].find(\"img\")[\"src\"]\n",
    "            short_bio = info_list[3].text\n",
    "            current_status = info_list[4].text\n",
    "            additional_info = info_list[-10].text\n",
    "            additional_info\n",
    "            publish_date = info.find(\"p\", attrs = {\"class\" : \"sou\"}).text\n",
    "\n",
    "            leader_info_dict.update({\n",
    "                \"name\" : name,\n",
    "                \"picture_url\" : picture,\n",
    "                \"short_bio\" : short_bio,\n",
    "                \"current_status\" : current_status,\n",
    "                \"additional_info\" : additional_info,\n",
    "                \"url\" : column[\"link\"],\n",
    "                \"publish_date\" : publish_date\n",
    "            })\n",
    "\n",
    "            leader_info_list.append(leader_info_dict)\n",
    "\n",
    "            for data in info_list[5:-9]:\n",
    "                leader_resume_dict = {}\n",
    "                try:\n",
    "                    year = data.text.split(\"年\")[0]\n",
    "                    content = data.text.split(\"年\")[1]\n",
    "                    leader_resume_dict.update({\n",
    "                        \"name\" : name,\n",
    "                        \"year\" : year,\n",
    "                        \"url\" : column[\"link\"],\n",
    "                        \"content\" : content\n",
    "                    })\n",
    "                except:\n",
    "                    content = data.text\n",
    "                    leader_resume_dict.update({\n",
    "                        \"name\" : name,\n",
    "                        \"url\" : column[\"link\"],\n",
    "                        \"content\" : content\n",
    "                    })\n",
    "                leader_resume_list.append(leader_resume_dict)\n",
    "    except:\n",
    "        print(column[\"link\"], \"has problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leader_resume_list = []\n",
    "leader_info_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cpc.people.com.cn/n1/2018/0319/c64094-29875773.html has problem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "20    None\n",
       "21    None\n",
       "22    None\n",
       "23    None\n",
       "24    None\n",
       "25    None\n",
       "26    None\n",
       "27    None\n",
       "28    None\n",
       "29    None\n",
       "      ... \n",
       "45    None\n",
       "46    None\n",
       "47    None\n",
       "48    None\n",
       "49    None\n",
       "50    None\n",
       "51    None\n",
       "52    None\n",
       "53    None\n",
       "54    None\n",
       "55    None\n",
       "56    None\n",
       "57    None\n",
       "58    None\n",
       "59    None\n",
       "60    None\n",
       "61    None\n",
       "62    None\n",
       "63    None\n",
       "64    None\n",
       "65    None\n",
       "66    None\n",
       "67    None\n",
       "68    None\n",
       "69    None\n",
       "70    None\n",
       "71    None\n",
       "72    None\n",
       "73    None\n",
       "74    None\n",
       "Length: 75, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(get_leader_info, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"http://cpc.people.com.cn/n1/2018/0319/c64094-29875773.html\" is a press release that somehow got in there\n",
    "#### beside that, everything else works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_leader_info = pd.DataFrame(leader_info_list)\n",
    "party_leader_info.to_csv(\"pl_info_dirty.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_leader_resume = pd.DataFrame(leader_resume_list)\n",
    "party_leader_resume.to_csv(\"pl_resume_dirty.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
